{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "913a5b8a",
   "metadata": {},
   "source": [
    "# Investigate Price Correlations w/ Fundamentals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd2a414",
   "metadata": {},
   "source": [
    "### For each metric of interest, X:\n",
    "\n",
    "- create by-year metric data, X per share\n",
    "- calculate the average ratio for price-to-X\n",
    "- rate the price correlations using the following ways:\n",
    "    - calculate the correlation between price and X\n",
    "    - plot the price against the price-per-average-price-to-X-ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5923494",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from yahoo_fin import stock_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308031c7",
   "metadata": {},
   "source": [
    "## Determine the earliest dates of price and financials data to include in analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fe17155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start date of quote history data: 2001-01-01 00:00:00\n",
      "Start year of financials history data: 2000\n"
     ]
    }
   ],
   "source": [
    "# set years interval for analysis\n",
    "analysis_interval_years = 20\n",
    "\n",
    "# get the earlist fiscal year accordingly\n",
    "start_year = datetime.utcnow().year - analysis_interval_years\n",
    "start_date_quote_history = datetime(start_year, 1, 1)\n",
    "start_year_financials_history = start_year - 1\n",
    "\n",
    "print(\"Start date of quote history data:\", start_date_quote_history)\n",
    "print(\"Start year of financials history data:\", start_year_financials_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802bd388",
   "metadata": {},
   "source": [
    "## Helper functions to pull and prep stock price data\n",
    "\n",
    "(updated 10/26/2021)\n",
    "\n",
    "- Switched from \"yfinance\" to \"yahoo_fin\" as the library to pull data from Yahoo Finance\n",
    "- <font color=blue>Validation OK</font>:\n",
    "    - Updated code tested on AAPL and the historical quotes now seem to be consistent with those on Yahoo Finance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8eb7486",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{datetime.datetime(2001, 1, 1, 0, 0): 0.3861609995365143,\n",
       " datetime.datetime(2001, 2, 1, 0, 0): 0.32589301466941833,\n",
       " datetime.datetime(2001, 3, 1, 0, 0): 0.39410701394081116,\n",
       " datetime.datetime(2001, 4, 1, 0, 0): 0.45517900586128235,\n",
       " datetime.datetime(2001, 5, 1, 0, 0): 0.35624998807907104,\n",
       " datetime.datetime(2001, 6, 1, 0, 0): 0.4151790142059326,\n",
       " datetime.datetime(2001, 7, 1, 0, 0): 0.33553600311279297,\n",
       " datetime.datetime(2001, 8, 1, 0, 0): 0.33125001192092896,\n",
       " datetime.datetime(2001, 9, 1, 0, 0): 0.276964008808136,\n",
       " datetime.datetime(2001, 10, 1, 0, 0): 0.3135710060596466,\n",
       " datetime.datetime(2001, 11, 1, 0, 0): 0.3803569972515106,\n",
       " datetime.datetime(2001, 12, 1, 0, 0): 0.39107099175453186,\n",
       " datetime.datetime(2002, 1, 1, 0, 0): 0.4414289891719818,\n",
       " datetime.datetime(2002, 2, 1, 0, 0): 0.38749998807907104,\n",
       " datetime.datetime(2002, 3, 1, 0, 0): 0.42267900705337524,\n",
       " datetime.datetime(2002, 4, 1, 0, 0): 0.4333930015563965,\n",
       " datetime.datetime(2002, 5, 1, 0, 0): 0.41607099771499634,\n",
       " datetime.datetime(2002, 6, 1, 0, 0): 0.3164289891719818,\n",
       " datetime.datetime(2002, 7, 1, 0, 0): 0.27250000834465027,\n",
       " datetime.datetime(2002, 8, 1, 0, 0): 0.26339301466941833,\n",
       " datetime.datetime(2002, 9, 1, 0, 0): 0.2589290142059326,\n",
       " datetime.datetime(2002, 10, 1, 0, 0): 0.2869639992713928,\n",
       " datetime.datetime(2002, 11, 1, 0, 0): 0.2767859995365143,\n",
       " datetime.datetime(2002, 12, 1, 0, 0): 0.2558929920196533,\n",
       " datetime.datetime(2003, 1, 1, 0, 0): 0.256428986787796,\n",
       " datetime.datetime(2003, 2, 1, 0, 0): 0.26803600788116455,\n",
       " datetime.datetime(2003, 3, 1, 0, 0): 0.2524999976158142,\n",
       " datetime.datetime(2003, 4, 1, 0, 0): 0.2539289891719818,\n",
       " datetime.datetime(2003, 5, 1, 0, 0): 0.3205359876155853,\n",
       " datetime.datetime(2003, 6, 1, 0, 0): 0.3403570055961609,\n",
       " datetime.datetime(2003, 7, 1, 0, 0): 0.3764289915561676,\n",
       " datetime.datetime(2003, 8, 1, 0, 0): 0.4037500023841858,\n",
       " datetime.datetime(2003, 9, 1, 0, 0): 0.3700000047683716,\n",
       " datetime.datetime(2003, 10, 1, 0, 0): 0.4087499976158142,\n",
       " datetime.datetime(2003, 11, 1, 0, 0): 0.3733929991722107,\n",
       " datetime.datetime(2003, 12, 1, 0, 0): 0.3816069960594177,\n",
       " datetime.datetime(2004, 1, 1, 0, 0): 0.4028570055961609,\n",
       " datetime.datetime(2004, 2, 1, 0, 0): 0.42714300751686096,\n",
       " datetime.datetime(2004, 3, 1, 0, 0): 0.48285698890686035,\n",
       " datetime.datetime(2004, 4, 1, 0, 0): 0.46035701036453247,\n",
       " datetime.datetime(2004, 5, 1, 0, 0): 0.5010709762573242,\n",
       " datetime.datetime(2004, 6, 1, 0, 0): 0.5810710191726685,\n",
       " datetime.datetime(2004, 7, 1, 0, 0): 0.5774999856948853,\n",
       " datetime.datetime(2004, 8, 1, 0, 0): 0.6158930063247681,\n",
       " datetime.datetime(2004, 9, 1, 0, 0): 0.6919639706611633,\n",
       " datetime.datetime(2004, 10, 1, 0, 0): 0.9357140064239502,\n",
       " datetime.datetime(2004, 11, 1, 0, 0): 1.1973210573196411,\n",
       " datetime.datetime(2004, 12, 1, 0, 0): 1.149999976158142,\n",
       " datetime.datetime(2005, 1, 1, 0, 0): 1.3732140064239502,\n",
       " datetime.datetime(2005, 2, 1, 0, 0): 1.6021430492401123,\n",
       " datetime.datetime(2005, 3, 1, 0, 0): 1.4882140159606934,\n",
       " datetime.datetime(2005, 4, 1, 0, 0): 1.2878570556640625,\n",
       " datetime.datetime(2005, 5, 1, 0, 0): 1.4199999570846558,\n",
       " datetime.datetime(2005, 6, 1, 0, 0): 1.3146430253982544,\n",
       " datetime.datetime(2005, 7, 1, 0, 0): 1.5232139825820923,\n",
       " datetime.datetime(2005, 8, 1, 0, 0): 1.6746430397033691,\n",
       " datetime.datetime(2005, 9, 1, 0, 0): 1.9146430492401123,\n",
       " datetime.datetime(2005, 10, 1, 0, 0): 2.056786060333252,\n",
       " datetime.datetime(2005, 11, 1, 0, 0): 2.42214298248291,\n",
       " datetime.datetime(2005, 12, 1, 0, 0): 2.567500114440918,\n",
       " datetime.datetime(2006, 1, 1, 0, 0): 2.6967859268188477,\n",
       " datetime.datetime(2006, 2, 1, 0, 0): 2.446070909500122,\n",
       " datetime.datetime(2006, 3, 1, 0, 0): 2.240000009536743,\n",
       " datetime.datetime(2006, 4, 1, 0, 0): 2.5139288902282715,\n",
       " datetime.datetime(2006, 5, 1, 0, 0): 2.134643077850342,\n",
       " datetime.datetime(2006, 6, 1, 0, 0): 2.0453569889068604,\n",
       " datetime.datetime(2006, 7, 1, 0, 0): 2.427143096923828,\n",
       " datetime.datetime(2006, 8, 1, 0, 0): 2.4232139587402344,\n",
       " datetime.datetime(2006, 9, 1, 0, 0): 2.749285936355591,\n",
       " datetime.datetime(2006, 10, 1, 0, 0): 2.895714044570923,\n",
       " datetime.datetime(2006, 11, 1, 0, 0): 3.273571014404297,\n",
       " datetime.datetime(2006, 12, 1, 0, 0): 3.0299999713897705,\n",
       " datetime.datetime(2007, 1, 1, 0, 0): 3.061785936355591,\n",
       " datetime.datetime(2007, 2, 1, 0, 0): 3.0217859745025635,\n",
       " datetime.datetime(2007, 3, 1, 0, 0): 3.318213939666748,\n",
       " datetime.datetime(2007, 4, 1, 0, 0): 3.56428599357605,\n",
       " datetime.datetime(2007, 5, 1, 0, 0): 4.328214168548584,\n",
       " datetime.datetime(2007, 6, 1, 0, 0): 4.3585710525512695,\n",
       " datetime.datetime(2007, 7, 1, 0, 0): 4.705714225769043,\n",
       " datetime.datetime(2007, 8, 1, 0, 0): 4.945713996887207,\n",
       " datetime.datetime(2007, 9, 1, 0, 0): 5.4810709953308105,\n",
       " datetime.datetime(2007, 10, 1, 0, 0): 6.783928871154785,\n",
       " datetime.datetime(2007, 11, 1, 0, 0): 6.507856845855713,\n",
       " datetime.datetime(2007, 12, 1, 0, 0): 7.074285984039307,\n",
       " datetime.datetime(2008, 1, 1, 0, 0): 4.834286212921143,\n",
       " datetime.datetime(2008, 2, 1, 0, 0): 4.465000152587891,\n",
       " datetime.datetime(2008, 3, 1, 0, 0): 5.125,\n",
       " datetime.datetime(2008, 4, 1, 0, 0): 6.212500095367432,\n",
       " datetime.datetime(2008, 5, 1, 0, 0): 6.7410712242126465,\n",
       " datetime.datetime(2008, 6, 1, 0, 0): 5.980000019073486,\n",
       " datetime.datetime(2008, 7, 1, 0, 0): 5.676785945892334,\n",
       " datetime.datetime(2008, 8, 1, 0, 0): 6.054643154144287,\n",
       " datetime.datetime(2008, 9, 1, 0, 0): 4.059286117553711,\n",
       " datetime.datetime(2008, 10, 1, 0, 0): 3.8424999713897705,\n",
       " datetime.datetime(2008, 11, 1, 0, 0): 3.309643030166626,\n",
       " datetime.datetime(2008, 12, 1, 0, 0): 3.0482139587402344,\n",
       " datetime.datetime(2009, 1, 1, 0, 0): 3.2189290523529053,\n",
       " datetime.datetime(2009, 2, 1, 0, 0): 3.189642906188965,\n",
       " datetime.datetime(2009, 3, 1, 0, 0): 3.754286050796509,\n",
       " datetime.datetime(2009, 4, 1, 0, 0): 4.493928909301758,\n",
       " datetime.datetime(2009, 5, 1, 0, 0): 4.8503570556640625,\n",
       " datetime.datetime(2009, 6, 1, 0, 0): 5.086785793304443,\n",
       " datetime.datetime(2009, 7, 1, 0, 0): 5.835357189178467,\n",
       " datetime.datetime(2009, 8, 1, 0, 0): 6.007500171661377,\n",
       " datetime.datetime(2009, 9, 1, 0, 0): 6.619643211364746,\n",
       " datetime.datetime(2009, 10, 1, 0, 0): 6.732142925262451,\n",
       " datetime.datetime(2009, 11, 1, 0, 0): 7.13964319229126,\n",
       " datetime.datetime(2009, 12, 1, 0, 0): 7.526071071624756,\n",
       " datetime.datetime(2010, 1, 1, 0, 0): 6.859285831451416,\n",
       " datetime.datetime(2010, 2, 1, 0, 0): 7.307857036590576,\n",
       " datetime.datetime(2010, 3, 1, 0, 0): 8.39285659790039,\n",
       " datetime.datetime(2010, 4, 1, 0, 0): 9.3246431350708,\n",
       " datetime.datetime(2010, 5, 1, 0, 0): 9.174285888671875,\n",
       " datetime.datetime(2010, 6, 1, 0, 0): 8.983214378356934,\n",
       " datetime.datetime(2010, 7, 1, 0, 0): 9.1875,\n",
       " datetime.datetime(2010, 8, 1, 0, 0): 8.682143211364746,\n",
       " datetime.datetime(2010, 9, 1, 0, 0): 10.133929252624512,\n",
       " datetime.datetime(2010, 10, 1, 0, 0): 10.749285697937012,\n",
       " datetime.datetime(2010, 11, 1, 0, 0): 11.112500190734863,\n",
       " datetime.datetime(2010, 12, 1, 0, 0): 11.520000457763672,\n",
       " datetime.datetime(2011, 1, 1, 0, 0): 12.118571281433105,\n",
       " datetime.datetime(2011, 2, 1, 0, 0): 12.614643096923828,\n",
       " datetime.datetime(2011, 3, 1, 0, 0): 12.446785926818848,\n",
       " datetime.datetime(2011, 4, 1, 0, 0): 12.504643440246582,\n",
       " datetime.datetime(2011, 5, 1, 0, 0): 12.422499656677246,\n",
       " datetime.datetime(2011, 6, 1, 0, 0): 11.988213539123535,\n",
       " datetime.datetime(2011, 7, 1, 0, 0): 13.945713996887207,\n",
       " datetime.datetime(2011, 8, 1, 0, 0): 13.743928909301758,\n",
       " datetime.datetime(2011, 9, 1, 0, 0): 13.618571281433105,\n",
       " datetime.datetime(2011, 10, 1, 0, 0): 14.456428527832031,\n",
       " datetime.datetime(2011, 11, 1, 0, 0): 13.649999618530273,\n",
       " datetime.datetime(2011, 12, 1, 0, 0): 14.464285850524902,\n",
       " datetime.datetime(2012, 1, 1, 0, 0): 16.3028564453125,\n",
       " datetime.datetime(2012, 2, 1, 0, 0): 19.37285614013672,\n",
       " datetime.datetime(2012, 3, 1, 0, 0): 21.412500381469727,\n",
       " datetime.datetime(2012, 4, 1, 0, 0): 20.856428146362305,\n",
       " datetime.datetime(2012, 5, 1, 0, 0): 20.633214950561523,\n",
       " datetime.datetime(2012, 6, 1, 0, 0): 20.85714340209961,\n",
       " datetime.datetime(2012, 7, 1, 0, 0): 21.812856674194336,\n",
       " datetime.datetime(2012, 8, 1, 0, 0): 23.75857162475586,\n",
       " datetime.datetime(2012, 9, 1, 0, 0): 23.825000762939453,\n",
       " datetime.datetime(2012, 10, 1, 0, 0): 21.261428833007812,\n",
       " datetime.datetime(2012, 11, 1, 0, 0): 20.902856826782227,\n",
       " datetime.datetime(2012, 12, 1, 0, 0): 19.006071090698242,\n",
       " datetime.datetime(2013, 1, 1, 0, 0): 16.267499923706055,\n",
       " datetime.datetime(2013, 2, 1, 0, 0): 15.764286041259766,\n",
       " datetime.datetime(2013, 3, 1, 0, 0): 15.809286117553711,\n",
       " datetime.datetime(2013, 4, 1, 0, 0): 15.813570976257324,\n",
       " datetime.datetime(2013, 5, 1, 0, 0): 16.061786651611328,\n",
       " datetime.datetime(2013, 6, 1, 0, 0): 14.161786079406738,\n",
       " datetime.datetime(2013, 7, 1, 0, 0): 16.161785125732422,\n",
       " datetime.datetime(2013, 8, 1, 0, 0): 17.400714874267578,\n",
       " datetime.datetime(2013, 9, 1, 0, 0): 17.02678680419922,\n",
       " datetime.datetime(2013, 10, 1, 0, 0): 18.667856216430664,\n",
       " datetime.datetime(2013, 11, 1, 0, 0): 19.859643936157227,\n",
       " datetime.datetime(2013, 12, 1, 0, 0): 20.036428451538086,\n",
       " datetime.datetime(2014, 1, 1, 0, 0): 17.878570556640625,\n",
       " datetime.datetime(2014, 2, 1, 0, 0): 18.794286727905273,\n",
       " datetime.datetime(2014, 3, 1, 0, 0): 19.169286727905273,\n",
       " datetime.datetime(2014, 4, 1, 0, 0): 21.074642181396484,\n",
       " datetime.datetime(2014, 5, 1, 0, 0): 22.60714340209961,\n",
       " datetime.datetime(2014, 6, 1, 0, 0): 23.232500076293945,\n",
       " datetime.datetime(2014, 7, 1, 0, 0): 23.899999618530273,\n",
       " datetime.datetime(2014, 8, 1, 0, 0): 25.625,\n",
       " datetime.datetime(2014, 9, 1, 0, 0): 25.1875,\n",
       " datetime.datetime(2014, 10, 1, 0, 0): 27.0,\n",
       " datetime.datetime(2014, 11, 1, 0, 0): 29.732500076293945,\n",
       " datetime.datetime(2014, 12, 1, 0, 0): 27.594999313354492,\n",
       " datetime.datetime(2015, 1, 1, 0, 0): 29.290000915527344,\n",
       " datetime.datetime(2015, 2, 1, 0, 0): 32.1150016784668,\n",
       " datetime.datetime(2015, 3, 1, 0, 0): 31.107500076293945,\n",
       " datetime.datetime(2015, 4, 1, 0, 0): 31.287500381469727,\n",
       " datetime.datetime(2015, 5, 1, 0, 0): 32.56999969482422,\n",
       " datetime.datetime(2015, 6, 1, 0, 0): 31.357500076293945,\n",
       " datetime.datetime(2015, 7, 1, 0, 0): 30.325000762939453,\n",
       " datetime.datetime(2015, 8, 1, 0, 0): 28.190000534057617,\n",
       " datetime.datetime(2015, 9, 1, 0, 0): 27.575000762939453,\n",
       " datetime.datetime(2015, 10, 1, 0, 0): 29.875,\n",
       " datetime.datetime(2015, 11, 1, 0, 0): 29.575000762939453,\n",
       " datetime.datetime(2015, 12, 1, 0, 0): 26.315000534057617,\n",
       " datetime.datetime(2016, 1, 1, 0, 0): 24.334999084472656,\n",
       " datetime.datetime(2016, 2, 1, 0, 0): 24.172500610351562,\n",
       " datetime.datetime(2016, 3, 1, 0, 0): 27.247499465942383,\n",
       " datetime.datetime(2016, 4, 1, 0, 0): 23.434999465942383,\n",
       " datetime.datetime(2016, 5, 1, 0, 0): 24.96500015258789,\n",
       " datetime.datetime(2016, 6, 1, 0, 0): 23.899999618530273,\n",
       " datetime.datetime(2016, 7, 1, 0, 0): 26.052499771118164,\n",
       " datetime.datetime(2016, 8, 1, 0, 0): 26.524999618530273,\n",
       " datetime.datetime(2016, 9, 1, 0, 0): 28.262500762939453,\n",
       " datetime.datetime(2016, 10, 1, 0, 0): 28.385000228881836,\n",
       " datetime.datetime(2016, 11, 1, 0, 0): 27.6299991607666,\n",
       " datetime.datetime(2016, 12, 1, 0, 0): 28.954999923706055,\n",
       " datetime.datetime(2017, 1, 1, 0, 0): 30.337499618530273,\n",
       " datetime.datetime(2017, 2, 1, 0, 0): 34.247501373291016,\n",
       " datetime.datetime(2017, 3, 1, 0, 0): 35.915000915527344,\n",
       " datetime.datetime(2017, 4, 1, 0, 0): 35.912498474121094,\n",
       " datetime.datetime(2017, 5, 1, 0, 0): 38.189998626708984,\n",
       " datetime.datetime(2017, 6, 1, 0, 0): 36.005001068115234,\n",
       " datetime.datetime(2017, 7, 1, 0, 0): 37.182498931884766,\n",
       " datetime.datetime(2017, 8, 1, 0, 0): 41.0,\n",
       " datetime.datetime(2017, 9, 1, 0, 0): 38.529998779296875,\n",
       " datetime.datetime(2017, 10, 1, 0, 0): 42.2599983215332,\n",
       " datetime.datetime(2017, 11, 1, 0, 0): 42.962501525878906,\n",
       " datetime.datetime(2017, 12, 1, 0, 0): 42.307498931884766,\n",
       " datetime.datetime(2018, 1, 1, 0, 0): 41.85749816894531,\n",
       " datetime.datetime(2018, 2, 1, 0, 0): 44.529998779296875,\n",
       " datetime.datetime(2018, 3, 1, 0, 0): 41.94499969482422,\n",
       " datetime.datetime(2018, 4, 1, 0, 0): 41.314998626708984,\n",
       " datetime.datetime(2018, 5, 1, 0, 0): 46.717498779296875,\n",
       " datetime.datetime(2018, 6, 1, 0, 0): 46.27750015258789,\n",
       " datetime.datetime(2018, 7, 1, 0, 0): 47.5724983215332,\n",
       " datetime.datetime(2018, 8, 1, 0, 0): 56.907501220703125,\n",
       " datetime.datetime(2018, 9, 1, 0, 0): 56.435001373291016,\n",
       " datetime.datetime(2018, 10, 1, 0, 0): 54.71500015258789,\n",
       " datetime.datetime(2018, 11, 1, 0, 0): 44.64500045776367,\n",
       " datetime.datetime(2018, 12, 1, 0, 0): 39.435001373291016,\n",
       " datetime.datetime(2019, 1, 1, 0, 0): 41.61000061035156,\n",
       " datetime.datetime(2019, 2, 1, 0, 0): 43.287498474121094,\n",
       " datetime.datetime(2019, 3, 1, 0, 0): 47.48749923706055,\n",
       " datetime.datetime(2019, 4, 1, 0, 0): 50.16749954223633,\n",
       " datetime.datetime(2019, 5, 1, 0, 0): 43.76750183105469,\n",
       " datetime.datetime(2019, 6, 1, 0, 0): 49.47999954223633,\n",
       " datetime.datetime(2019, 7, 1, 0, 0): 53.2599983215332,\n",
       " datetime.datetime(2019, 8, 1, 0, 0): 52.185001373291016,\n",
       " datetime.datetime(2019, 9, 1, 0, 0): 55.99250030517578,\n",
       " datetime.datetime(2019, 10, 1, 0, 0): 62.189998626708984,\n",
       " datetime.datetime(2019, 11, 1, 0, 0): 66.8125,\n",
       " datetime.datetime(2019, 12, 1, 0, 0): 73.4124984741211,\n",
       " datetime.datetime(2020, 1, 1, 0, 0): 77.37750244140625,\n",
       " datetime.datetime(2020, 2, 1, 0, 0): 68.33999633789062,\n",
       " datetime.datetime(2020, 3, 1, 0, 0): 63.5724983215332,\n",
       " datetime.datetime(2020, 4, 1, 0, 0): 73.44999694824219,\n",
       " datetime.datetime(2020, 5, 1, 0, 0): 79.48500061035156,\n",
       " datetime.datetime(2020, 6, 1, 0, 0): 91.19999694824219,\n",
       " datetime.datetime(2020, 7, 1, 0, 0): 106.26000213623047,\n",
       " datetime.datetime(2020, 8, 1, 0, 0): 129.0399932861328,\n",
       " datetime.datetime(2020, 9, 1, 0, 0): 115.80999755859375,\n",
       " datetime.datetime(2020, 10, 1, 0, 0): 108.86000061035156,\n",
       " datetime.datetime(2020, 11, 1, 0, 0): 119.05000305175781,\n",
       " datetime.datetime(2020, 12, 1, 0, 0): 132.69000244140625,\n",
       " datetime.datetime(2021, 1, 1, 0, 0): 131.9600067138672,\n",
       " datetime.datetime(2021, 2, 1, 0, 0): 121.26000213623047,\n",
       " datetime.datetime(2021, 3, 1, 0, 0): 122.1500015258789,\n",
       " datetime.datetime(2021, 4, 1, 0, 0): 131.4600067138672,\n",
       " datetime.datetime(2021, 5, 1, 0, 0): 124.61000061035156,\n",
       " datetime.datetime(2021, 6, 1, 0, 0): 136.9600067138672,\n",
       " datetime.datetime(2021, 7, 1, 0, 0): 145.86000061035156,\n",
       " datetime.datetime(2021, 8, 1, 0, 0): 151.8300018310547,\n",
       " datetime.datetime(2021, 9, 1, 0, 0): 141.5,\n",
       " datetime.datetime(2021, 10, 1, 0, 0): 148.63999938964844,\n",
       " datetime.datetime(2021, 10, 26, 0, 0): 149.32000732421875}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_payload_json_quote_history_from_yfinance_df(df_quote_history, header='close'):\n",
    "    \"\"\"\n",
    "    This helper function gets a cleaned-up payload json/dict from the dataframe of \n",
    "    historical quotes, which is returned by yfinance api (yfinance.Ticker('<symbol>').history)\n",
    "    \"\"\"\n",
    "    \n",
    "    _payload_json = {}\n",
    "    _df = df_quote_history[header]\n",
    "    \n",
    "    # loop through all timestamps in the data:\n",
    "    for timestamp in dict(_df):\n",
    "        if not np.isnan(_df[timestamp]):\n",
    "            _payload_json[timestamp.to_pydatetime()] = _df[timestamp]\n",
    "            \n",
    "    return _payload_json\n",
    "\n",
    "\n",
    "def get_quote_history(symbol, start, end, interval='1mo', header='close'):\n",
    "    \"\"\"\n",
    "    This helper function pulls raw historical quote data using the YFinance API, \n",
    "    and returns the cleaned up data in a dictionary of \"<timestamp>: <price>\".\n",
    "    \"\"\"\n",
    "    \n",
    "    # initialize an yfinance object, and get the historical quote data \n",
    "    # from the API\n",
    "    df_quote_history = stock_info.get_data(symbol, start_date=start, end_date=end, \n",
    "                                           interval=interval)\n",
    "    \n",
    "    # return a \"timestamp\": \"price\" dictionary from the dataframe of historical quotes\n",
    "    return get_payload_json_quote_history_from_yfinance_df(df_quote_history, \n",
    "                                                           header=header)\n",
    "\n",
    "\n",
    "# testing\n",
    "\n",
    "aapl_quote_history = get_quote_history('AAPL', \n",
    "                                       start=start_date_quote_history.strftime('%m/%d/%Y'),\n",
    "                                       end=datetime.utcnow().strftime('%m/%d/%Y'))\n",
    "aapl_quote_history\n",
    "\n",
    "# testing successful"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac60c9c5",
   "metadata": {},
   "source": [
    "## Helper functions to pull and prep stock fundamentals data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24aa193e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_guru_data(symbol, data_type, api_token='b4bbdecd0f955e18a90fee818670dd94:42afdf0e68bee024983a72f8b6ad071d'):\n",
    "    \"\"\"\n",
    "    This helper function pulls data from the GuruFocus API, for the given symbol\n",
    "    and data type.\n",
    "    \"\"\"\n",
    "    \n",
    "    base_url = 'https://api.gurufocus.com/public/user/' + api_token + '/stock/'\n",
    "    constructed_url = base_url + symbol + '/' + data_type\n",
    "    \n",
    "    r = requests.get(constructed_url)\n",
    "    if r.status_code != 200:\n",
    "        return \"Error: the GuruFocus API service failed.\"\n",
    "    else:\n",
    "        return r.json()\n",
    "    \n",
    "\n",
    "# testing\n",
    "\n",
    "aapl_financials_history = get_guru_data('AAPL', 'financials')\n",
    "aapl_financials_history\n",
    "\n",
    "# testing successful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43806b9a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class FinancialMetric(object):\n",
    "    \"\"\"\n",
    "    This class implements financial metrics as objects, along with \n",
    "    related operations.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, name, timestamps, start_year, values, numerify_values=True, drop_timestamps=['TTM']):\n",
    "        \"\"\"\n",
    "        Constructor.\n",
    "        \n",
    "        Input:\n",
    "            - \"name\": name of the metric.\n",
    "            - \"timestamps\": a list (or list-like) of strings in the format of \"%Y-%m\"\n",
    "            - \"start_year\": the earliest year in the input data to be used\n",
    "            - \"values\": a list (or list-like) of values (could be strings) for the metric,\n",
    "                        with each value corresponding to the timestamp value of the same position\n",
    "                        in the input list of timestamps\n",
    "            - \"numerify_values\": default=True; \n",
    "                                 if True attempt to convert all input values to float values\n",
    "            - \"drop_values\": default=['TTM']; \n",
    "                             a list of strings to be removed from the input timestamps\n",
    "                             list, and the associated value will also be removed from the input values \n",
    "                             list.\n",
    "        \"\"\"\n",
    "        \n",
    "        # if requested, ensure all values are converted to numeric values (float)\n",
    "        if numerify_values:\n",
    "            _values = [float(value) for value in values]\n",
    "        else:\n",
    "            _values = values\n",
    "\n",
    "        # zip the two lists to form a dictionary\n",
    "        _data = dict(zip(timestamps, _values))\n",
    "\n",
    "        # form a new dictionary with pre-specified contraints on the \"year\" values\n",
    "        _processed_data = {}\n",
    "        for timestamp in _data:\n",
    "            if timestamp in drop_timestamps:\n",
    "                continue\n",
    "            _timestamp_obj = datetime.strptime(timestamp, '%Y-%m')\n",
    "            if _timestamp_obj.year >= start_year:\n",
    "                _processed_data[_timestamp_obj] = _data[timestamp]\n",
    "        \n",
    "        # save the processed timestamps and values\n",
    "        self.name = name\n",
    "        self.timestamps = tuple(_processed_data.keys())\n",
    "        self.values = tuple(_processed_data.values())\n",
    "        \n",
    "    def get_raw_data(self):\n",
    "        \"\"\"\n",
    "        This method returns the saved timestamps & values as a dictionary of \"timestamp: value\" pairs.\n",
    "        \"\"\"\n",
    "        \n",
    "        return dict(zip(self.timestamps, self.values))\n",
    "    \n",
    "    def set_per_share_data(self, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        This method sets the per share values for the current metric.\n",
    "        \"\"\"\n",
    "        \n",
    "        if 'x_total' in kwargs and 'x_per_share' in kwargs:\n",
    "            if len(kwargs['x_total']) != len(self.values) or len(kwargs['x_total']) != len(kwargs['x_per_share']):\n",
    "                raise ValueError('Invalid length(s) of values.')\n",
    "            else:\n",
    "                _total_shares = np.array(kwargs['x_total']) / kwargs['x_per_share']\n",
    "                self.per_share_values = list(np.array(self.values) / _total_shares)\n",
    "                \n",
    "    def get_per_share_data(self):\n",
    "        \"\"\"\n",
    "        This method returns the saved timestamps & per share values as a dictionary of\n",
    "        \"<timestamp>: <per share value>\"\n",
    "        \"\"\"\n",
    "        \n",
    "        return dict(zip(self.timestamps, self.per_share_values))\n",
    "        \n",
    "        \n",
    "# testing\n",
    "aapl_ebit = FinancialMetric(name = 'ebit', \n",
    "                            timestamps = aapl_financials_history['financials']['annuals']['Fiscal Year'],\n",
    "                            start_year = start_year_financials_history,\n",
    "                            values = aapl_financials_history['financials']['annuals']['income_statement']['EBIT'])\n",
    "aapl_ebit.get_raw_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6898701d",
   "metadata": {},
   "source": [
    "### <font color=red>TODO - revamp the current logic for calculating per share data</font>\n",
    "\n",
    "- Use the \"sharings outstanding (average diluated)\" data from Guru (income statement) instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224fb10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "aapl_revenue = FinancialMetric(name='revenue',\n",
    "                               timestamps=aapl_financials_history['financials']['annuals']['Fiscal Year'],\n",
    "                               start_year=start_year_financials_history,\n",
    "                               values=aapl_financials_history['financials']['annuals']['income_statement']['Revenue'])\n",
    "aapl_revenue_per_share = FinancialMetric(name='revenue per share',\n",
    "                                         timestamps=aapl_financials_history['financials']['annuals']['Fiscal Year'],\n",
    "                                         start_year=start_year_financials_history,\n",
    "                                         values=aapl_financials_history['financials']['annuals']['per_share_data_array']['Revenue per Share'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94b6a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "aapl_ebit.set_per_share_data(x_total=aapl_revenue.values, x_per_share=aapl_revenue_per_share.values)\n",
    "aapl_ebit.get_per_share_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5d73d8",
   "metadata": {},
   "source": [
    "## Helper function to calculate the average Price-to-X ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317af309",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_avg_price_ratio(price_data, per_share_metric_data):\n",
    "    \"\"\"\n",
    "    This function calculates and returns the average price-to-metric ratio.\n",
    "    \n",
    "    Input:\n",
    "        - \"price_data\" - dictionary of \"<timestamp>: <price>\"\n",
    "        - \"per_share_metric_data\" - dictionary of \"<timestamp>: <per share metric value>\", \n",
    "                                    with timestamps at the year level\n",
    "    \"\"\"\n",
    "    \n",
    "    # convert the keys of the per share metric dictionary from timestamps to years\n",
    "    _years = [timestamp.year for timestamp in per_share_metric_data.keys()]\n",
    "    _metric_values_by_year = dict(zip(_years, list(per_share_metric_data.values())))\n",
    "    \n",
    "    # get new dictionaries for timestamps where both price and metric value are available\n",
    "    _merged_data = {}\n",
    "    for key in price_data:\n",
    "        _metric_value = _metric_values_by_year.get(key.year)\n",
    "        if _metric_value:\n",
    "            _merged_data[key] = (price_data[key], _metric_value, \n",
    "                                 price_data[key]/_metric_value)\n",
    "\n",
    "    # put all price-to-metric ratios into a list\n",
    "    _ratios = [_merged_data[key][-1] for key in _merged_data]\n",
    "    \n",
    "    return sum(_ratios) / len(_ratios)\n",
    "    \n",
    "\n",
    "# testing\n",
    "calc_avg_price_ratio(aapl_quote_history, aapl_ebit.get_per_share_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8d74cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_normal_price(per_share_metric_data, avg_price_to_x_ratio):\n",
    "    \"\"\"\n",
    "    This function calculates and returns the \"normal price\" with respect to \n",
    "    a specific income/cash flow metric X:\n",
    "    \n",
    "        \"normal price\" = \"historical price\" x \"historical average Price-to-X ratio\"\n",
    "\n",
    "    Inputs:\n",
    "        - \"per_share_metric_data\": dictionary of \"<timestamp>: <per share metric value>\"\n",
    "        - \"avg_price_to_x_ratio\": a numerical value\n",
    "        \n",
    "    Output:\n",
    "        - \"normal price\": see above\n",
    "    \"\"\"\n",
    "    \n",
    "    return {timestamp: max(0, per_share_metric_data[timestamp] * avg_price_to_x_ratio) \\\n",
    "            for timestamp in per_share_metric_data}\n",
    "\n",
    "\n",
    "# testing\n",
    "aapl_normal_price_per_ebit = get_normal_price(aapl_ebit.get_per_share_data(), \n",
    "                                              calc_avg_price_ratio(aapl_quote_history, aapl_ebit.get_per_share_data()))\n",
    "aapl_normal_price_per_ebit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc778bce",
   "metadata": {},
   "source": [
    "## Chart price vs normal price (per metric X) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff2877d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.models import DatetimeTickFormatter, NumeralTickFormatter\n",
    "from bokeh.plotting import figure, show\n",
    "from bokeh.io import output_notebook\n",
    "\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f2a170",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(quote_history_data, normal_price_data):\n",
    "    \"\"\"\n",
    "    This helper function\n",
    "    \"\"\"\n",
    "    \n",
    "    # create new plot\n",
    "    p = figure(title = \"Price Correlated with Fundamentals\",\n",
    "               x_axis_type = \"datetime\",\n",
    "               x_axis_label= \"Time\",\n",
    "               y_axis_label= \"Price\")\n",
    "\n",
    "    # add a line for historical prices by month\n",
    "    p.line(list(quote_history_data.keys()), \n",
    "           list(quote_history_data.values()), \n",
    "           legend_label='Price', \n",
    "           color='black',\n",
    "           line_width=2)\n",
    "\n",
    "    # add a line for \"normal prices\" by year\n",
    "    p.line(list(normal_price_data.keys()),\n",
    "           list(normal_price_data.values()),\n",
    "           legend_label = 'Normal Price',\n",
    "           line_width = 2)\n",
    "\n",
    "    show(p)\n",
    "    \n",
    "\n",
    "# testing\n",
    "plot(aapl_quote_history, aapl_normal_price_per_ebit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222cfe0f",
   "metadata": {},
   "source": [
    "## Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4f2142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters - choose a company\n",
    "symbol = 'CAT'\n",
    "\n",
    "# get financial history\n",
    "financials_history = get_guru_data(symbol, 'financials')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a96465d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters - experiment\n",
    "\n",
    "# set years interval for analysis\n",
    "analysis_interval_years = 20\n",
    "\n",
    "# financials parameters\n",
    "section_name = 'income_statement'\n",
    "metric_name = 'EBITDA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84a4d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the earlist fiscal year accordingly\n",
    "start_year = datetime.utcnow().year - analysis_interval_years\n",
    "start_date_quote_history = datetime(start_year, 1, 1)\n",
    "start_year_financials_history = start_year - 1\n",
    "\n",
    "# get quote history\n",
    "quote_history = get_quote_history(symbol, start=start_date_quote_history.strftime('%Y-%m-%d'),\n",
    "                                  end=datetime.utcnow().strftime('%Y-%m-%d'))\n",
    "\n",
    "# get revenue and revenue per share\n",
    "revenue = FinancialMetric(name='revenue',\n",
    "                          timestamps=financials_history['financials']['annuals']['Fiscal Year'],\n",
    "                          start_year=start_year_financials_history,\n",
    "                          values=financials_history['financials']['annuals']['income_statement']['Revenue'])\n",
    "revenue_per_share = FinancialMetric(name='revenue per share',\n",
    "                                    timestamps=financials_history['financials']['annuals']['Fiscal Year'],\n",
    "                                    start_year=start_year_financials_history,\n",
    "                                    values=financials_history['financials']['annuals']['per_share_data_array']['Revenue per Share'])\n",
    "\n",
    "# get per share metric data\n",
    "metric_X = FinancialMetric(name = metric_name, \n",
    "                           timestamps = financials_history['financials']['annuals']['Fiscal Year'],\n",
    "                           start_year = start_year_financials_history,\n",
    "                           values = financials_history['financials']['annuals'][section_name][metric_name])\n",
    "\n",
    "metric_X.set_per_share_data(x_total=revenue.values, x_per_share=revenue_per_share.values)\n",
    "\n",
    "# get normal prices for metric X\n",
    "normal_price_per_X = get_normal_price(metric_X.get_per_share_data(), \n",
    "                                      calc_avg_price_ratio(quote_history, metric_X.get_per_share_data()))\n",
    "\n",
    "# plot\n",
    "plot(quote_history, normal_price_per_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d323ff7",
   "metadata": {},
   "source": [
    "# <font color=blue>Moderate data issues with per share financials from Guru</font>\n",
    "\n",
    "- It seems like the per share financials from Guru is not always properly split adjusted\n",
    "- For example, there was a 2-to-1 split in 2004 for \"CAT\"\n",
    "- And the per share \"EBIDTA\" value for 2004 from the Guru API (see below) are clearly not properly adjusted\n",
    "- The # of outstanding shares data for 2004 is also obviously wrong\n",
    "- Tested a few more companies:\n",
    "    - Checked \"AAPL\" and \"EPD\"\n",
    "        - Both companies had splits\n",
    "        - <font color=blue>**Good news**</font> - It seems both the # of outstanding shares data and the per share financials data were correct for years close to the splits\n",
    "- Some minor differences were also observed when comparing for example \"EBIT/share\" from FastGraphs and Guru\n",
    "    - Guru's total EBIT (using Apple as an example) seemed to be consistent with that of Yahoo Finance\n",
    "    - Guru's shares outstanding (average diluted) also seemed to be consistent with that of Yahoo Finance\n",
    "    - So despite some minor differences noticed when compared to FastGraphs, Guru's data should be mostly good\n",
    "    \n",
    "<font color=blue>**Conclusions**</font>\n",
    "- Guru's financials data seems to be mostly alright - nothing much to worry about"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fe8e79",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "financials_history['financials']['annuals']['income_statement'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76edae2e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get oustanding shares by year\n",
    "dict(zip(financials_history['financials']['annuals']['Fiscal Year'], financials_history['financials']['annuals']['income_statement']['Shares Outstanding (Diluted Average)']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77906ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get EBIDTA per share by year\n",
    "dict(zip(financials_history['financials']['annuals']['Fiscal Year'], financials_history['financials']['annuals']['per_share_data_array']['EBITDA per Share']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7084d2d",
   "metadata": {},
   "source": [
    "# <font color=red>Severe data issues with quote data and next steps</font> \n",
    "\n",
    "- The historical quotes returned by the yfinance API (by RAN AROUSSI) are not correct for dates in earlier years\n",
    "    - For example, see the tests below for 'CAT'. I also observed issues for at least 'EPD'.\n",
    "- **Next steps**: test and validate other options to get historical quotes, such as the 'yahoo_fin' library\n",
    "    - See a guide here for the 'yahoo_fin' library - https://algotrading101.com/learn/yahoo-finance-api-guide/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c3f15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f66733b",
   "metadata": {},
   "outputs": [],
   "source": [
    "_stock = yf.Ticker('CAT')\n",
    "_stock.history(interval='1mo', \n",
    "               start=start_date_quote_history.strftime('%Y-%m-%d'),\n",
    "               end=datetime.utcnow().strftime('%Y-%m-%d'))['Close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee2d0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "_stock.splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f1a8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "_stock.history(interval='1mo', \n",
    "               start=start_date_quote_history.strftime('%Y-%m-%d'),\n",
    "               end=datetime.utcnow().strftime('%Y-%m-%d'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0edad01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
